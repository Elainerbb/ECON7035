{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h0TTuGB8ssz5"
   },
   "source": [
    "## 1. The MNIST Data\n",
    "\n",
    "The [MNIST](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/mnist/load_data) data is a database of handwritten digit images. It contains 60K 28x28 grayscale images in the training set and 10K images in the test set. Each image shows a 10-digit number ranged between 0-9.\n",
    "\n",
    "- ``x_train``: NumPy array of grayscale image data with shape (60000, 28, 28).  \n",
    "\n",
    "- ``y_train``: NumPy array of digit labels (integers in range 0-9) with shape (60000,).\n",
    "\n",
    "- ``x_test``: NumPy array of grayscale image data with shape (10000, 28, 28).  \n",
    "\n",
    "- ``y_test``: NumPy array of digit labels with shape (10000,).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VZnNvywjcFt"
   },
   "source": [
    "### 1.1 Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 9046,
     "status": "ok",
     "timestamp": 1710489225595,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "HtXDMyEQrn_x",
    "outputId": "dde2f65c-be68-4ee4-ffc1-3a0df0d990e1"
   },
   "outputs": [],
   "source": [
    "#uncomment below codes to ignore the certificate verification requirement if you run this notebook on a macOS system\n",
    "#import ssl\n",
    "#ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "display(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aGY0QZt4EEHB"
   },
   "source": [
    "Let's take a look of the 1st image, which is a 28 * 28 matrix.\n",
    "\n",
    "- As the image is grayscale, each pixel contains only one integer value (ranged from 0 to 255):  0 represent black, 255 represents white.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1710489225595,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "dgC8bKv7sxzo",
    "outputId": "cff2ecc8-8f2d-45b1-8f67-75c89c1a1c92"
   },
   "outputs": [],
   "source": [
    "print(X_train[0])     #alternatively, print(X_train[0, :, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JUCyNycvrn_x"
   },
   "source": [
    "### 1.2 Select 24 Images Randomly for Display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710489225595,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "L_TT4VGudrvl",
    "outputId": "11c4e6ea-7ea3-4531-d6aa-ca414a50adeb"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.RandomState(0)                                  # random seed at 0\n",
    "index = rng.choice(np.arange(len(X_train)), 24, replace=False)  # generate 24 indices randomly\n",
    "\n",
    "X_train24 = X_train[index]\n",
    "y_train24 = y_train[index]\n",
    "\n",
    "display(X_train24.shape, y_train24.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 674
    },
    "executionInfo": {
     "elapsed": 2318,
     "status": "ok",
     "timestamp": 1710489227910,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "ntc_A7lTrn_y",
    "outputId": "74b926a6-ceae-4d5b-f5fa-a0f64e6f4f70"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(12, 8))         # a figure with 4 * 6 subplots (axes is a 2D array)\n",
    "\n",
    "# loop over the flattened axes, image, and target label\n",
    "# numpy.ravel() falttens the 2D axes as a 1D array to loop over\n",
    "for axes, image, target in zip(axes.ravel(), X_train24, y_train24):\n",
    "    axes.matshow(image, cmap = plt.cm.gray_r)      # display each image (28*28 matrix) with reversed gray scale\n",
    "    axes.set_xticks([])                            # remove x-axis tick marks\n",
    "    axes.set_yticks([])                            # remove y-axis tick marks\n",
    "    axes.set_title(target)                         # set target value as subplot title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Viti3heoSVN1"
   },
   "source": [
    "## 2. Prepare the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5Qrq17X8rn_y"
   },
   "source": [
    "### 2.1 Reshape and Scale Features\n",
    "\n",
    "CNN in Keras require the features as 4D array with the shape `(no. of images., width, height, channels)`, so we need to reshape the 3D ``X_train`` and ``X_test`` into 4D by adding a 4th dimension.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710489227910,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "KFQIRoL6rn_y",
    "outputId": "d545df98-a130-4e33-e615-8d5d8ba78b16"
   },
   "outputs": [],
   "source": [
    "# reshape from 3D to 4D (1 element in the 4th Dimension)\n",
    "\n",
    "X_train_new = X_train.reshape((60000, 28, 28, 1))\n",
    "X_test_new = X_test.reshape((10000, 28, 28, 1))\n",
    "\n",
    "display(X_train.shape, X_test.shape, X_train_new.shape, X_test_new.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w4L5Yr1Wrn_y"
   },
   "source": [
    "Deep learning networks perform better on scaled data (both MinMax and StandardScaler will do). Let's simply normalize the pixel values by min-max scaling.\n",
    "\n",
    "- Also, neutral network in keras requires `X` as a floating point tensor, not integers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K3ANos8GjAwD"
   },
   "outputs": [],
   "source": [
    "X_train_new = X_train_new/ 255\n",
    "X_test_new = X_test_new/ 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "415VRMw9rn_y"
   },
   "source": [
    "### 2.2 Reshape Target Variable\n",
    "\n",
    "The target variable is a 1D array with a class label for each image. There are two approaches to handle it in a multi-class classification task.\n",
    "\n",
    "\n",
    "- Encode the original class labels as ``integer tensor`` (i.e., a 1D array with ``no. of instance`` values), which is what we have now. <font color = 'green'> **See part2 of Week9_NNs for demonstration.**<font>\n",
    "\n",
    "- Apply `one-hot encoding`(also known as `categorical encoding`) to the labels so that the 1D array will be transformed as a 2D array in the shape `no. of instance * no. of classes`. Each row is a vector with all `0`s but a `1` in the place of the label index.   <font color='red'>**We take this approach for demonstration purpose.**<font>\n",
    "\n",
    "  Technically, `One-hot` encoding can be done with (1)  the `tensorflow.keras.layers.CategoryEncoding` function with `output_mode = 'one_hot'` (check [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/layers/CategoryEncoding) for details); or (2) the `tensorflow.keras.utils.to_categorical` function (check [documentation](https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical) for details).\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1710489228520,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "e3heCTn7rn_z",
    "outputId": "972e6a09-8289-4e39-8446-51a8f20f91a4"
   },
   "outputs": [],
   "source": [
    "# one-hot encoding to class labels\n",
    "\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "y_train_new = to_categorical(y_train)\n",
    "y_test_new  = to_categorical(y_test)\n",
    "display(y_train.shape, y_test.shape, y_train_new.shape, y_test_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710489228520,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "qjt6C4rcrn_z",
    "outputId": "cfb54a84-8057-481b-b50c-612dc670a45e"
   },
   "outputs": [],
   "source": [
    "# check target of the first 10 training images\n",
    "\n",
    "display(y_train[:10], y_train_new[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PFNDFQR5SjWc"
   },
   "source": [
    "## 3. Build a CNN model on Training Set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D0R8R17Irn_z"
   },
   "source": [
    "### 3.1 Define a CNN Model\n",
    "\n",
    "1. The first hidden layer is [``Conv2D`` layer](https://keras.io/api/layers/convolution_layers/convolution2d/) with below setting. Note the input is `28 x 28 x 1` for each image, output is `26 x 26 x 64`.\n",
    "\n",
    "> - ``filters``= 64: the number of filters in the resulting feature map.\n",
    "> - ``kernel_size``= (3, 3): the size of the kernel used in each filter.\n",
    "> -  ``strides``=(1, 1) (default)\n",
    "> -  ``padding``= 'valid' (default, no padding)\n",
    "> - ``activation``= 'relu': the 'relu' (Rectified Linear Unit) activation function.\n",
    "\n",
    "\n",
    "2. The second hidden layer is a [``MaxPooling2D`` layer](https://keras.io/api/layers/pooling_layers/max_pooling2d/). With below setting, it reduces the previous layer’s output from `26 x 26 x 64` to `13 x 13 x 64` (i.e., 75% reduction)\n",
    "\n",
    "> - ``pool_size``=(2, 2) (default)\n",
    "> - ``strides``= None (default to `pool_size`)\n",
    "\n",
    "3. Then we use another `Conv2D` layer with 128 filters (size 3*3) followed by another `MaxPooling2D` layer.\n",
    "\n",
    "> - The input to the 2nd `Conv2D` layer is `13 x 13 x 64`, then the output will be `11 x 11 x 128` as the kernel size is (3,3).\n",
    "> - For odd dimensions like 11 x 11, the `MaxPooling2D` layer rounds down (here to 10 x 10), so output will be `5 x 5 x 128`.\n",
    "\n",
    "4. Flatten the 3D output of the 2nd `MaxPooling2D` layer as a 1D array with 3200 values (i.e., 5 * 5 * 128) with a `Flatten layer` (check [here](https://keras.io/api/layers/reshaping_layers/flatten/) for details).  \n",
    "\n",
    "5. A CNN model contains **at least one `Dense` Layer**, here we have two: the first `Dense` layer create new features, the second (with `softmax` activation) is the output layer which returns 10 probabilities for each image.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CW6UmCqUrn_z"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "cnn = Sequential()\n",
    "cnn.add(Conv2D(filters=64, kernel_size=(3, 3),  activation='relu'))   # use default value for strides and padding\n",
    "cnn.add(MaxPooling2D())                                               # default pool_size and strides\n",
    "cnn.add(Conv2D(filters=128, kernel_size=(3, 3), activation='relu'))\n",
    "cnn.add(MaxPooling2D())\n",
    "cnn.add(Flatten())\n",
    "cnn.add(Dense(units = 128, activation='relu'))\n",
    "cnn.add(Dense(units = 10, activation='softmax'))    # output probabilities of 10 classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d66TV_YDr4xI"
   },
   "source": [
    "### 3.2 Compile and Train the Model  \n",
    "\n",
    "The modeling training process is the same as a feed-forward neural network.\n",
    "\n",
    "- Note that with ``one-hot encoding`` applied to target labels, we should use ``categorical_crossentropy`` as the loss function here.  If the target labels are in the format of `integer tensor` (e.g., original labels), we should use `` sparse_categorical_crossentropy`` loss.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 623417,
     "status": "ok",
     "timestamp": 1710489851933,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "YCD-LViyrn_z",
    "outputId": "a374d888-2e9e-45a0-b9ed-b93ed3f7a9d4"
   },
   "outputs": [],
   "source": [
    "# compile the model\n",
    "cnn.compile(optimizer='adam',                   # other optimizers work as well\n",
    "            loss='categorical_crossentropy',    # with one-hot encoding, use `categorical_crossentropy` as loss function\n",
    "            metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# train the model (it may take a while due to the big training size)\n",
    "cnn.fit(x = X_train_new,         # use reshaped x_train\n",
    "        y = y_train_new,         # use reshaped y_train\n",
    "        epochs=5,\n",
    "        batch_size= 5000,        # use a big batch size to speed up training\n",
    "        validation_split = 0.2)  # 20% saved for validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3wVfSr4k_ETl"
   },
   "source": [
    "### 3.3 Model Summary and Visualization\n",
    "\n",
    "How many parameters to learn? 485K!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1710489851933,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "JhV0SdSL_DQ8",
    "outputId": "5da06505-0fba-440b-d721-76084267f9e4"
   },
   "outputs": [],
   "source": [
    "cnn.summary()      # No. of instances as None (omitted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zkqxub-jIsYz"
   },
   "source": [
    "\n",
    "Alternatively, we can also display the model summary in a more readable format.\n",
    "\n",
    "- Here we visualze the model and (optionally) save it as a `png` or `jpeg` picture in Google Drive, with `plot_model` function from `tensorflow.keras.utils` module  (check [here](https://keras.io/api/utils/model_plotting_utils/) for details).\n",
    "- We can load it back for display later with the `Image` function from `IPython` (check [here](https://ipython.readthedocs.io/en/stable/api/generated/IPython.display.html#IPython.display.Image) for details).  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2357,
     "status": "ok",
     "timestamp": 1710489854288,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "2GLwwpgkM7pJ",
    "outputId": "25f80b3d-8fa7-4012-9c81-444719d9d7c8"
   },
   "outputs": [],
   "source": [
    "# connect Google Drive with Colab first\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 865
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1710489854288,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "LcwhKvbHrn_z",
    "outputId": "4b1f6db1-366c-4144-f3e7-e7a6a30bbba2"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model\n",
    "from IPython.display import Image\n",
    "\n",
    "# Option 1: save in Google Drive(so that we can find it later), need to mount drive first.\n",
    "plot_model(cnn, to_file='/content/drive/MyDrive/Colab Notebooks/Deep Learning/cnn.png', show_shapes=True,  show_layer_names=True)\n",
    "#Image(filename='/content/drive/MyDrive/Colab Notebooks/Deep Learning/cnn.png')       # load and display the saved image\n",
    "\n",
    "\n",
    "# Option 2: save the pic as a temp file in runtime (no need to mount drive). Note temp file will be gone once the runtime is closed.\n",
    "#plot_model(cnn, to_file='cnn.png', show_shapes=True,  show_layer_names=True)\n",
    "#Image(filename='cnn.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SacbgbLnL2HY"
   },
   "source": [
    "## 4. Model Evaluation on Test Set\n",
    "\n",
    "Let's take this model as the final model and test its performance on test data. Please complete below blocks.\n",
    "\n",
    "- Use ``X_test_new`` and ``y_test_new`` for prediction and testing.\n",
    "- You may noticed that the `batch_size` in model evaluation is by default 32."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bU0X56nBoYYH"
   },
   "source": [
    "### 4.1 Estimate Class Probabilities\n",
    "\n",
    "<font color=red>***Exercise 1: Your Codes Here***</font>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "executionInfo": {
     "elapsed": 10346,
     "status": "ok",
     "timestamp": 1710489864631,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "eW2k-GA9rn_z",
    "outputId": "a9bda975-68ed-4ae3-d0bd-460297d8e3d0"
   },
   "outputs": [],
   "source": [
    "predictions = cnn.predict(X_test_new)\n",
    "\n",
    "# Display the shape of the result and probabilities for the first image\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fbwAEogJXyE_"
   },
   "source": [
    "### 4.2 Get Predicted Class Labels  \n",
    "\n",
    "<font color=red>***Exercise 2: Your Codes Here***</font>  \n",
    "\n",
    "As class label is the same as column index in the probability matrix, let's\n",
    "return col indices of the maximum probability for each image (row).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1710489864631,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "G4bxTc_4XSsl",
    "outputId": "02061adf-902b-460f-fd94-a4572dfcac48"
   },
   "outputs": [],
   "source": [
    "#Return the indices of the maximum values along an axis (1 means col)\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSxgRTYSocjx"
   },
   "source": [
    "### 4.3 Check Model loss and Accuracy  \n",
    "\n",
    "<font color=red>***Exercise 3: Your Codes Here***</font>  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 10369,
     "status": "ok",
     "timestamp": 1710489874998,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "SJo48NyTrn_z",
    "outputId": "debde58d-cfe1-4942-c95c-a1fe89f164f2"
   },
   "outputs": [],
   "source": [
    "loss, accuracy = cnn.evaluate(X_test_new, y_test_new)\n",
    "\n",
    "# Display the lost and accuracy\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5V648u14YT8p"
   },
   "source": [
    "### 4.4 Locate Incorrect Predictions\n",
    "\n",
    "<font color=red>***Exercise 4: Your Codes Here***</font>  \n",
    "\n",
    "Please use ``X_test`` and ``y_test`` for visualization here, as ``X_test_new`` is scaled version of  ``X_test`` in the range of [0.1]  and ``y_test_new`` is 2D.\n",
    "\n",
    "- **Step 1**: obtain the feature values, actual and predicted class labels for incorrect predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1710489874999,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "1Jku8FTph4yq",
    "outputId": "a11ba33e-1ae4-4c4c-f24b-997780a1dbcd"
   },
   "outputs": [],
   "source": [
    "X_test2 = X_test[predicted_labels != y_test]\n",
    "y_test2 = y_test[predicted_labels != y_test]\n",
    "y_pred2 = predicted_labels[predicted_labels != y_test]\n",
    "\n",
    "display(X_test2.shape, y_test2.shape, y_pred2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OAwtBSK3l3k_"
   },
   "source": [
    "- **Step 2**:  Randomly select 24 mis-classified images for visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1710489874999,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "Eg6uzF76-BaL",
    "outputId": "6ae7ecda-be07-472b-db30-1364e0e102a2"
   },
   "outputs": [],
   "source": [
    "rng = np.random.RandomState(1)                                  # random seed at 1\n",
    "# your code here (reference to 1.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yjP6VB7rFwMh"
   },
   "source": [
    "- **Step 3**: visualize the feature matrix as heatmap. You may also visualize their actual and predicted class labels for comparison. Looking at the digits, you can see why handwritten digit recognition is a challenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 815
    },
    "executionInfo": {
     "elapsed": 2146,
     "status": "ok",
     "timestamp": 1710489877140,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "oyF9GOYCiU7S",
    "outputId": "82e6420d-4e3d-44c0-f844-bc57d0c4426b"
   },
   "outputs": [],
   "source": [
    "figure, axes = plt.subplots(nrows=4, ncols=6, figsize=(12, 10))\n",
    "\n",
    "# loop over the axes, image pixels, actual and predicted label\n",
    "# your code here (reference to 1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mkd2ZWNLmGQX"
   },
   "source": [
    "## 5. Save and load a model\n",
    "\n",
    "The `save` method of Keras models (check [here](https://www.tensorflow.org/guide/keras/serialization_and_saving) for details) stores the model's architecture, weights, and training configuration in a single `model.keras` zip archive.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nQKSg3Ybrn_0"
   },
   "outputs": [],
   "source": [
    "#Save in my Google Drive (mount drive first)\n",
    "cnn.save(\"/content/drive/MyDrive/Colab Notebooks/Deep Learning/cnn.keras\")\n",
    "\n",
    "#Alternatively, save the model as a temp file in runtime (which will be gone when this runtime is closed)\n",
    "#cnn.save('cnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DF2_yNplnkiW"
   },
   "source": [
    "Load the model with the `load_model` function from  `tensorflow.keras.models` module. With a model loaded, we can apply it for prediction or evaluation, or check the summary easily.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 629,
     "status": "ok",
     "timestamp": 1710489877764,
     "user": {
      "displayName": "Jing Liu",
      "userId": "15589682681165269292"
     },
     "user_tz": -480
    },
    "id": "c2TzuSpwnpjI",
    "outputId": "2584efc4-bcd9-4fc8-b1da-3da7f45bc768"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "cnn_reloaded = load_model(\"/content/drive/MyDrive/Colab Notebooks/Deep Learning/cnn.keras\")\n",
    "cnn_reloaded.summary()\n",
    "\n",
    "#Alternatively, reload the temp file saved in runtime (before closing the runtime)\n",
    "#cnn_reloaded = load_model('cnn.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_UnWCpxbq5nL"
   },
   "source": [
    "**Extension: Data Augmentation**\n",
    "\n",
    "To augment image data in order to avoid overfitting, we may add augmentation layers in the model as well. For details, please visit [this link](https://keras.io/api/layers/preprocessing_layers/image_augmentation/)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
